{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526b86f6",
   "metadata": {},
   "source": [
    "# Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7ed1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import os\n",
    "import folium\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af836f16",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc72c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "df = pd.read_csv('/Users/buketoztekin/Documents/Cleaned_Salaries_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "478f1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propt matplotlib visuals to appear in the notebook \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ed0b007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Analytics Engineer</td>\n",
       "      <td>59615</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>AI Developer</td>\n",
       "      <td>252000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>AI Developer</td>\n",
       "      <td>168000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>199500</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>86700</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year experience_level employment_type           job_title  \\\n",
       "0       2024               MI              FT  Analytics Engineer   \n",
       "1       2024               SE              FT        AI Developer   \n",
       "2       2024               SE              FT        AI Developer   \n",
       "3       2024               MI              FT      Data Scientist   \n",
       "4       2024               MI              FT      Data Scientist   \n",
       "\n",
       "   salary_in_usd employee_residence  remote_ratio company_location  \\\n",
       "0          59615                 CA           100               CA   \n",
       "1         252000                 US             0               US   \n",
       "2         168000                 US             0               US   \n",
       "3         199500                 US           100               US   \n",
       "4          86700                 US           100               US   \n",
       "\n",
       "  company_size  \n",
       "0            S  \n",
       "1            M  \n",
       "2            M  \n",
       "3            M  \n",
       "4            M  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1a9ded3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/buketoztekin/Documents/world-countries.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m country_geo \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/buketoztekin/Documents/world-countries.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# That's just in case you want to look at the JSON file contents here too:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Open the JSON file and load it into a dictionary\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(country_geo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Print the top-level keys to understand the structure\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/buketoztekin/Documents/world-countries.json'"
     ]
    }
   ],
   "source": [
    "# File path to your JSON file for the world countries\n",
    "country_geo = r'/Users/buketoztekin/Documents/world-countries.json'\n",
    "\n",
    "# That's just in case you want to look at the JSON file contents here too:\n",
    "# Open the JSON file and load it into a dictionary\n",
    "with open(country_geo, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Print the top-level keys to understand the structure\n",
    "print(data.keys())\n",
    "\n",
    "# If the 'features' key exists (common in GeoJSON), let's print the first feature\n",
    "if 'features' in data:\n",
    "    print(json.dumps(data['features'][0], indent=2))  # Print the first feature with pretty formatting\n",
    "else:\n",
    "    print(\"The 'features' key does not exist in the GeoJSON file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bb37ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['type', 'features'])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dumps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3_/dyc73j694fb41h6xln2l5_rc0000gn/T/ipykernel_57251/3119663997.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# If the 'features' key exists, let's print the first feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'features'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Print the first feature to inspect its structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The 'features' key does not exist in the GeoJSON file.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6293\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6294\u001b[0m         ):\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dumps'"
     ]
    }
   ],
   "source": [
    "# Print the top-level keys to understand the structure\n",
    "print(data.keys())\n",
    "\n",
    "# If the 'features' key exists, let's print the first feature\n",
    "if 'features' in data:\n",
    "    # Print the first feature to inspect its structure\n",
    "    print(json.dumps(data['features'][0], indent=2))\n",
    "else:\n",
    "    print(\"The 'features' key does not exist in the GeoJSON file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feba971",
   "metadata": {},
   "source": [
    "### In the JSON file, the properties are shown as full country names (name : Afghanistan). Therefore, I need to create new columns with country names to match with their ISO codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d2fee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Za...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Zi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type                                           features\n",
       "0    FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Af...\n",
       "1    FeatureCollection  {'type': 'Feature', 'properties': {'name': 'An...\n",
       "2    FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Al...\n",
       "3    FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Un...\n",
       "4    FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Ar...\n",
       "..                 ...                                                ...\n",
       "172  FeatureCollection  {'type': 'Feature', 'properties': {'name': 'We...\n",
       "173  FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Ye...\n",
       "174  FeatureCollection  {'type': 'Feature', 'properties': {'name': 'So...\n",
       "175  FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Za...\n",
       "176  FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Zi...\n",
       "\n",
       "[177 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f106de",
   "metadata": {},
   "source": [
    "### In order to match the country codes with full names, I will use pycountry library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "426af82f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'employee_residence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'employee_residence'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m code\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Apply to dataframe creating new columns\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memployee_country_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memployee_residence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(get_country_name_from_code)\n\u001b[1;32m     13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_country_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_location\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(get_country_name_from_code)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'employee_residence'"
     ]
    }
   ],
   "source": [
    "import pycountry\n",
    "\n",
    "# Function to convert country code to country name\n",
    "def get_country_name_from_code(code):\n",
    "    try:\n",
    "        country = pycountry.countries.get(alpha_2=code)\n",
    "        return country.name\n",
    "    except:\n",
    "        return code\n",
    "\n",
    "# Apply to dataframe creating new columns\n",
    "df['employee_country_name'] = df['employee_residence'].apply(get_country_name_from_code)\n",
    "df['company_country_name'] = df['company_location'].apply(get_country_name_from_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c38ba8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Za...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>FeatureCollection</td>\n",
       "      <td>{'type': 'Feature', 'properties': {'name': 'Zi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type                                           features\n",
       "0    FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Af...\n",
       "1    FeatureCollection  {'type': 'Feature', 'properties': {'name': 'An...\n",
       "2    FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Al...\n",
       "3    FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Un...\n",
       "4    FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Ar...\n",
       "..                 ...                                                ...\n",
       "172  FeatureCollection  {'type': 'Feature', 'properties': {'name': 'We...\n",
       "173  FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Ye...\n",
       "174  FeatureCollection  {'type': 'Feature', 'properties': {'name': 'So...\n",
       "175  FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Za...\n",
       "176  FeatureCollection  {'type': 'Feature', 'properties': {'name': 'Zi...\n",
       "\n",
       "[177 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba9e28",
   "metadata": {},
   "source": [
    "## Check for missing values in the new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "359ea6bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['employee_country_name', 'company_country_name'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check for missing values in 'employee_country_name' and 'company_country_name' columns\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m missing_values \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memployee_country_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_country_name\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(missing_values)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['employee_country_name', 'company_country_name'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Check for missing values in 'employee_country_name' and 'company_country_name' columns\n",
    "missing_values = df[['employee_country_name', 'company_country_name']].isnull().sum()\n",
    "\n",
    "# Display the result\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a566e",
   "metadata": {},
   "source": [
    "## Convert data types of the new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259153a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'employee_country_name' and 'company_country_name' to string (object) type\n",
    "df['employee_country_name'] = df['employee_country_name'].astype(str)\n",
    "df['company_country_name'] = df['company_country_name'].astype(str)\n",
    "\n",
    "# Verify the data type changes\n",
    "print(df[['employee_country_name', 'company_country_name']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f370593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d2bedb1",
   "metadata": {},
   "source": [
    "##  Check Country Name Matching Between DataFrame and GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load your GeoJSON file\n",
    "file_path = '/Users/buketoztekin/Documents/world_countries.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    try:\n",
    "        geo_json_data = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error loading JSON file: {e}\")\n",
    "        geo_json_data = None\n",
    "\n",
    "# Check if the GeoJSON was loaded successfully\n",
    "if geo_json_data and 'features' in geo_json_data:\n",
    "    # Extract all country names from the GeoJSON file\n",
    "    geojson_countries = []\n",
    "    \n",
    "    # Loop through features to extract the country names\n",
    "    for feature in geo_json_data['features']:\n",
    "        if 'properties' in feature and 'name' in feature['properties']:\n",
    "            geojson_countries.append(feature['properties']['name'])\n",
    "        else:\n",
    "            print(f\"Missing 'properties' or 'name' in feature: {feature}\")\n",
    "    \n",
    "    # Print the list of country names\n",
    "    print(geojson_countries)\n",
    "else:\n",
    "    print(\"The 'features' key does not exist in the GeoJSON file or the file failed to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique country names in 'company_country_name' column\n",
    "company_countries = df['company_country_name'].unique()\n",
    "print(\"Unique country names in 'company_country_name':\")\n",
    "print(company_countries)\n",
    "\n",
    "# Check unique country names in 'employee_country_name' column\n",
    "employee_countries = df['employee_country_name'].unique()\n",
    "print(\"\\nUnique country names in 'employee_country_name':\")\n",
    "print(employee_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9fd20",
   "metadata": {},
   "source": [
    "### There are a few mismatch. To correct this, I will create a dictionary that maps the country names in the DataFrame to those in the GeoJSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map country names from your dataset to those in the GeoJSON\n",
    "country_name_mapping = {\n",
    "    'United States': 'United States of America',\n",
    "    'Türkiye': 'Turkey',\n",
    "    'Viet Nam': 'Vietnam',\n",
    "    'Korea, Republic of': 'South Korea',\n",
    "    'Russian Federation': 'Russia',\n",
    "    'Czechia': 'Czech Republic',\n",
    "    'Iran, Islamic Republic of': 'Iran',\n",
    "    'Moldova, Republic of': 'Moldova',\n",
    "    'Bolivia, Plurinational State of': 'Bolivia',\n",
    "    'Iran, Islamic Republic of': 'Iran'\n",
    "}\n",
    "\n",
    "# Apply the mapping to fix country names in your DataFrame\n",
    "df['company_country_name'] = df['company_country_name'].replace(country_name_mapping)\n",
    "df['employee_country_name'] = df['employee_country_name'].replace(country_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3370cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique country names in 'company_country_name' column\n",
    "company_countries = df['company_country_name'].unique()\n",
    "print(\"Unique country names in 'company_country_name':\")\n",
    "print(company_countries)\n",
    "\n",
    "# Check unique country names in 'employee_country_name' column\n",
    "employee_countries = df['employee_country_name'].unique()\n",
    "print(\"\\nUnique country names in 'employee_country_name':\")\n",
    "print(employee_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d272d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "274388f6",
   "metadata": {},
   "source": [
    "## Creating a Choropleth Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a89aa31",
   "metadata": {},
   "source": [
    "I will create the map based on the average salary per country, using the company's location as the reference point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame with just the company countries and the salaries\n",
    "\n",
    "data_to_plot = df[['company_country_name','salary_in_usd']]\n",
    "data_to_plot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bcce1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e76bb618",
   "metadata": {},
   "source": [
    "### Choropleth map for average salary and company location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average salary per country\n",
    "average_salary_per_country = data_to_plot.groupby('company_country_name')['salary_in_usd'].mean().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "average_salary_per_country.columns = ['company_country_name', 'average_salary_in_usd']\n",
    "\n",
    "# Check the result\n",
    "print(average_salary_per_country.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0866e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for any missing values in the average salary data\n",
    "missing_data = average_salary_per_country[average_salary_per_country['average_salary_in_usd'].isna()]\n",
    "print(\"Countries with missing salary data:\", missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e6ed06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4788c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the folium map, center the map on the world\n",
    "map = folium.Map(location=[20, 0], zoom_start=2)\n",
    "\n",
    "# Create the Choropleth map with the average salary\n",
    "choropleth = folium.Choropleth(\n",
    "    geo_data=geo_json_data,  # Loaded GeoJSON data\n",
    "    data=average_salary_per_country,  # Data with the average salary\n",
    "    columns=['company_country_name', 'average_salary_in_usd'],  # Use average salary column\n",
    "    key_on='feature.properties.name',  # Matching country names from GeoJSON\n",
    "    fill_color='RdPu',  # Color scale\n",
    "    fill_opacity=0.6,  # Opacity of the fill\n",
    "    line_opacity=0.2,  # Opacity of the country borders\n",
    "    legend_name=\"Average Salary in USD\",  # Legend title\n",
    "    nan_fill_color=\"white\",  # Color for missing values\n",
    "    highlight=True  # Highlight feature when hovering\n",
    ").add_to(map)\n",
    "\n",
    "# Add a layer control for toggling map elements (optional)\n",
    "folium.LayerControl().add_to(map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(\"choropleth_map_average_salary.html\")\n",
    "\n",
    "# Display the map\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ecc817",
   "metadata": {},
   "source": [
    "The highest average salaries are paid in Qatar, followed by Israel, Saudi Arabia, the United States, Canada, Australia, Egypt, and Switzerland. In Europe, eastern and southern countries tend to offer lower salaries compared to the rest of the continent. Meanwhile, Mexico and Colombia stand out in Central and South America, offering higher average salaries than their regional counterparts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aae443",
   "metadata": {},
   "source": [
    "### Choropleth map for maximum salary and company location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb47176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate maximum salary per country\n",
    "maximum_salary_per_country = data_to_plot.groupby('company_country_name')['salary_in_usd'].max().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "maximum_salary_per_country.columns = ['company_country_name', 'maximum_salary_in_usd']\n",
    "\n",
    "# Check the result\n",
    "print(maximum_salary_per_country.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the folium map, center the map on the world\n",
    "map = folium.Map(location=[20, 0], zoom_start=2)\n",
    "\n",
    "# Create the Choropleth map with the average salary\n",
    "choropleth = folium.Choropleth(\n",
    "    geo_data=geo_json_data,  # Loaded GeoJSON data\n",
    "    data=maximum_salary_per_country,  # Data with the average salary\n",
    "    columns=['company_country_name', 'maximum_salary_in_usd'],  # Use maximum salary column\n",
    "    key_on='feature.properties.name',  # Matching country names from GeoJSON\n",
    "    fill_color='RdPu',  # Color scale\n",
    "    fill_opacity=0.6,  # Opacity of the fill\n",
    "    line_opacity=0.2,  # Opacity of the country borders\n",
    "    legend_name=\"Maximum Salary in USD\",  # Legend title\n",
    "    nan_fill_color=\"white\",  # Color for missing values\n",
    "    highlight=True  # Highlight feature when hovering\n",
    ").add_to(map)\n",
    "\n",
    "# Add a layer control for toggling map elements (optional)\n",
    "folium.LayerControl().add_to(map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(\"choropleth_map_maximum_salary.html\")\n",
    "\n",
    "# Display the map\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f674ec1",
   "metadata": {},
   "source": [
    "The highest-paid individuals are in the USA and Qatar, followed by the UK. This suggests a significant gap between the average and maximum salaries, or greater salary variation within these countries. A similar pattern appears in Russia, which shows a darker shade on the \"maximum salary\" map but a lighter shade on the \"average salary\" map compared to other countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average remote work ratio by country (using company location)\n",
    "average_remote_work_by_country = df.groupby('company_country_name')['remote_ratio'].mean().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "average_remote_work_by_country.columns = ['company_country_name', 'average_remote_ratio']\n",
    "\n",
    "# Check the result\n",
    "print(average_remote_work_by_country.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022eca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_remote_work_by_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d66b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the folium map, center the map on the world\n",
    "remote_work_map = folium.Map(location=[20, 0], zoom_start=2)\n",
    "\n",
    "# Add choropleth layer for average remote work ratio\n",
    "choropleth = folium.Choropleth(\n",
    "    geo_data=geo_json_data,  # Loaded GeoJSON data\n",
    "    data=average_remote_work_by_country,  # Data with the average remote work ratio\n",
    "    columns=['company_country_name', 'average_remote_ratio'],  # Use average remote work ratio\n",
    "    key_on='feature.properties.name',  # Matching country names from GeoJSON\n",
    "    fill_color='PuRd',  # Use a Purple-Red color scale\n",
    "    fill_opacity=0.6,  # Opacity of the fill\n",
    "    line_opacity=0.2,  # Opacity of the country borders\n",
    "    legend_name=\"Average Remote Work Ratio\",\n",
    "    nan_fill_color=\"lightgray\",  # Color for missing values\n",
    "    highlight=True  # Highlight feature when hovering\n",
    ").add_to(remote_work_map)\n",
    "\n",
    "# Add a layer control for toggling map elements (optional)\n",
    "folium.LayerControl().add_to(remote_work_map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "remote_work_map.save(\"average_remote_work_map.html\")\n",
    "\n",
    "# Display the map\n",
    "remote_work_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd062b01",
   "metadata": {},
   "source": [
    "Countries with a higher average remote work ratio include Brazil, Argentina, Chile, Mexico, Greece, Ecuador, Sweden, and Poland, where companies tend to have more remote workers compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208907fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7910cf8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Additional analysis without the extreme salary values for 2023 - 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491576c8",
   "metadata": {},
   "source": [
    "In my earlier analysis, I created the choropleth maps using salary data from all available years (2020, 2021, 2022, 2023, and 2024). However, the majority of the data points were concentrated in the recent years—especially in 2024, followed by 2023 and 2022. There was very little data for 2020 and 2021, which could skew the results when comparing trends across all years.\n",
    "\n",
    "Given this, I decided to focus on 2023 and 2024 to capture the most recent trends in AI/ML job salaries. This approach allows me to provide a clearer and more accurate picture of the current salary landscape without the influence of outdated data.\n",
    "\n",
    "#### Handling Outliers in Salary Data\n",
    "Additionally, upon reviewing the data, I identified that some salaries were extremely high, likely representing outliers. These outliers can distort the overall analysis by inflating averages and giving a skewed perception of typical salaries in this field. To address this issue, I applied a quartile-based filtering approach, where I removed extreme values by focusing on the interquartile range (IQR). This method helps to keep the data within a more reasonable range, making the map more reflective of the general salary distribution without the influence of a few high salaries.\n",
    "\n",
    "#### Objective of the New Maps\n",
    "This new map, focusing on 2023–2024 data, provides a more accurate, up-to-date view of AI/ML job salaries across countries, adjusted to exclude extreme outliers. This way, it highlights more representative salary data and recent market trends, offering a clearer understanding of the current job market without distortion from either outdated data or unusually high salary points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary_in_usd'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f5481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "mean_salary = 146558.036405\n",
    "std_salary = 69283.705335\n",
    "\n",
    "# Define the threshold for extreme values (mean ± 2 * standard deviation)\n",
    "upper_threshold = mean_salary + 2 * std_salary\n",
    "lower_threshold = mean_salary - 2 * std_salary\n",
    "\n",
    "print(\"Upper Threshold (mean + 2*std):\", upper_threshold)\n",
    "print(\"Lower Threshold (mean - 2*std):\", lower_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d23244a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'salary_in_usd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'salary_in_usd'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Remove the extreme salary values based on the thresholds\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary_in_usd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m285125.44707500003\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m      3\u001b[0m                                 (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary_in_usd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7990.62573499998\u001b[39m)]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Check the size of the cleaned dataset\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'salary_in_usd'"
     ]
    }
   ],
   "source": [
    "# Remove the extreme salary values based on the thresholds\n",
    "df_filtered = df[(df['salary_in_usd'] <= 285125.44707500003) & \n",
    "                                (df['salary_in_usd'] >= 7990.62573499998)]\n",
    "\n",
    "# Check the size of the cleaned dataset\n",
    "print(\"Original Size:\", len(df))\n",
    "print(\"Cleaned Size:\", len(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f4286",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(df_filtered['salary_in_usd'], bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_2023_2024 = df_filtered[(df_filtered['work_year'] >= 2023) & (df_filtered['work_year'] <= 2024)]\n",
    "# Print the unique values from the 'work_year' column\n",
    "print(\"Unique values in 'work_year':\", df_filtered_2023_2024['work_year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69994b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b7d860b",
   "metadata": {},
   "source": [
    "## Creating New Choropleth Maps Based on Filtered Salary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525fd4e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a data frame with just the company countries and the salaries\n",
    "\n",
    "data_to_plot2 = df_filtered_2023_2024[['company_country_name','salary_in_usd']]\n",
    "data_to_plot2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b39d28f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group by company_country_name and calculate the average salary\n",
    "average_salary_per_country2 = data_to_plot2.groupby('company_country_name').mean().reset_index()\n",
    "average_salary_per_country2.columns = ['company_country_name', 'average_salary_in_usd']  \n",
    "\n",
    "# Check the result\n",
    "average_salary_per_country2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319597c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup the folium map, center the map on the world\n",
    "map = folium.Map(location=[20, 0], zoom_start=2)\n",
    "\n",
    "# Create the Choropleth map with the average salary\n",
    "choropleth = folium.Choropleth(\n",
    "    geo_data=geo_json_data,  # Loaded GeoJSON data\n",
    "    data=average_salary_per_country2,  # Data with the average salary\n",
    "    columns=['company_country_name', 'average_salary_in_usd'],  # Use average salary column\n",
    "    key_on='feature.properties.name',  # Matching country names from GeoJSON\n",
    "    fill_color='OrRd',  # Color scale\n",
    "    fill_opacity=0.6,  # Opacity of the fill\n",
    "    line_opacity=0.2,  # Opacity of the country borders\n",
    "    legend_name=\"Average Salary in 2023 & 2024 (in USD)\",  # Legend title\n",
    "    nan_fill_color=\"white\",  # Color for missing values\n",
    "    highlight=True  # Highlight feature when hovering\n",
    ").add_to(map)\n",
    "\n",
    "# Add a layer control for toggling map elements (optional)\n",
    "folium.LayerControl().add_to(map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(\"choropleth_map_average_salary_2023&2024.html\")\n",
    "\n",
    "# Display the map\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08f00df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group by company_country_name and calculate the average salary\n",
    "maximum_salary_per_country2 = data_to_plot2.groupby('company_country_name').max().reset_index()\n",
    "maximum_salary_per_country2.columns = ['company_country_name', 'maximum_salary_in_usd']  \n",
    "\n",
    "# Check the result\n",
    "maximum_salary_per_country2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the folium map, center the map on the world\n",
    "map = folium.Map(location=[20, 0], zoom_start=2)\n",
    "\n",
    "# Create the Choropleth map with the average salary\n",
    "choropleth = folium.Choropleth(\n",
    "    geo_data=geo_json_data,  # Loaded GeoJSON data\n",
    "    data=maximum_salary_per_country2,  # Data with the average salary\n",
    "    columns=['company_country_name', 'maximum_salary_in_usd'],  # Use average salary column\n",
    "    key_on='feature.properties.name',  # Matching country names from GeoJSON\n",
    "    fill_color='OrRd',  # Color scale\n",
    "    fill_opacity=0.6,  # Opacity of the fill\n",
    "    line_opacity=0.2,  # Opacity of the country borders\n",
    "    legend_name=\"Maximum Salary in 2023 & 2024 (in USD)\",  # Legend title\n",
    "    nan_fill_color=\"white\",  # Color for missing values\n",
    "    highlight=True  # Highlight feature when hovering\n",
    ").add_to(map)\n",
    "\n",
    "# Add a layer control for toggling map elements (optional)\n",
    "folium.LayerControl().add_to(map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(\"choropleth_map_average_salary_2023&2024.html\")\n",
    "\n",
    "# Add a layer control for toggling map elements (optional)\n",
    "folium.LayerControl().add_to(map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(\"choropleth_map_average_salary_2023_2024.html\")\n",
    "\n",
    "# Display the map\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de574ea",
   "metadata": {},
   "source": [
    "# Exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the new dataframe with the country columns\n",
    "df.to_csv('/Users/buketoztekin/Documents/Cleaned_salaries_with_country_columns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece20dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
